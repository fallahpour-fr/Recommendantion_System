{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import copy\n",
    "from utils import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = {\n",
    "    'movie1': ['Action', 'Adventure'],\n",
    "    'movie2': ['Comedy', 'Romance'],\n",
    "    'movie3': ['Drama'],\n",
    "    'movie4': ['Action', 'Drama'],\n",
    "    'movie5': ['Comedy', 'Adventure'],\n",
    "    'movie6': ['Action', 'Adventure'],\n",
    "    'movie7': ['Comedy', 'Romance'],\n",
    "    'movie8': ['Drama']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movie):\n",
    "    # Get the genres of the movie\n",
    "    genres = movies[movie]\n",
    "    \n",
    "    # Initialize an empty list to store recommended movies\n",
    "    recommendations = []\n",
    "    \n",
    "    # Loop through all the movies\n",
    "    for other_movie, other_genres in movies.items():\n",
    "        # Skip the movie we are comparing to\n",
    "        if other_movie == movie:\n",
    "            continue\n",
    "        \n",
    "        # Calculate the similarity score between the genres of the two movies\n",
    "        similarity_score = len(set(genres) & set(other_genres)) / float(len(set(genres) | set(other_genres)))\n",
    "        \n",
    "        # Add the movie and similarity score to the recommendations list if the similarity score is greater than 0.5\n",
    "        if similarity_score > 0.5:\n",
    "            recommendations.append((other_movie, similarity_score))\n",
    "            \n",
    "    # Sort the recommendations by similarity score in descending order\n",
    "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the top 3 recommendations\n",
    "    return recommendations[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie6\n"
     ]
    }
   ],
   "source": [
    "# Get recommendations for movie1\n",
    "recommendations = get_recommendations('movie1')\n",
    "\n",
    "# Print the recommended movies\n",
    "for recommendation in recommendations:\n",
    "    print(recommendation[0])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice LinearLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(Module):\n",
    "    \"\"\"\n",
    "    A linear layer module which calculate (Wx + b).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim_in, dim_out, initializer, reg, alpha):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            - dim_in: input dimension,\n",
    "            - dim_out: output dimension,\n",
    "            - initializer: a function which get (dim_in, dim_out) and initialize\n",
    "                a [dim_in x dim_out] matrix,\n",
    "            - reg: L2-regularization flag\n",
    "            - alpha: L2-regularization coefficient\n",
    "        \"\"\"\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        self.params = {\n",
    "            #########################################\n",
    "            ##          Initialize parameters      ##\n",
    "            ##              Your Code              ##\n",
    "            #########################################\n",
    "            'W': None,\n",
    "            'b': None\n",
    "        }\n",
    "        self.grads = dict()\n",
    "        self.cache = dict()\n",
    "\n",
    "    def _forward(self, x):\n",
    "        \"\"\"\n",
    "        linear forward function, calculate Wx+b for a batch of data\n",
    "\n",
    "        Args:\n",
    "            x : a batch of data\n",
    "         Note:\n",
    "            you need to store some values in cache to be able to\n",
    "            calculate backward path.\n",
    "        \"\"\"\n",
    "        #########################################\n",
    "        ##              Your Code              ##\n",
    "        #########################################\n",
    "        y = None\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, upstream):\n",
    "        \"\"\"\n",
    "        get upstream gradient and returns downstream gradient\n",
    "\n",
    "        Args:\n",
    "            upstream : upstream gradient of loss w.r.t module output\n",
    "\n",
    "        Note:\n",
    "            you need to calculate gradient of loss w.r.t module input\n",
    "            and parameters and store them in grads.\n",
    "        \"\"\"\n",
    "        #########################################\n",
    "        ##              Your Code              ##\n",
    "        #########################################\n",
    "        grad_b = None\n",
    "        grad_w = None\n",
    "        grad_x = None\n",
    "        grad_reg = None\n",
    "\n",
    "        self.grads = {\n",
    "            'W': grad_w,\n",
    "            'b': grad_b,\n",
    "            'x': grad_x,\n",
    "            'reg': grad_reg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = lambda x, y: np.random.normal(size=(y, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x, y)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\mohemmmmm\\personal-projects\\mohem\\ML\\mohem-ml\\recommendation-system\\practise-nyral-networ.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mohemmmmm/personal-projects/mohem/ML/mohem-ml/recommendation-system/practise-nyral-networ.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m initializer \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x, y: np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(size\u001b[39m=\u001b[39m(y, x))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/mohemmmmm/personal-projects/mohem/ML/mohem-ml/recommendation-system/practise-nyral-networ.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m linear \u001b[39m=\u001b[39m LinearLayer(\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m, initializer, reg\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, alpha\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/mohemmmmm/personal-projects/mohem/ML/mohem-ml/recommendation-system/practise-nyral-networ.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m check_gradient_linear(linear, h\u001b[39m=\u001b[39;49m\u001b[39m0.00001\u001b[39;49m)\n",
      "File \u001b[1;32md:\\mohemmmmm\\personal-projects\\mohem\\ML\\mohem-ml\\recommendation-system\\utils.py:84\u001b[0m, in \u001b[0;36mcheck_gradient_linear\u001b[1;34m(linear, h)\u001b[0m\n\u001b[0;32m     81\u001b[0m upstream \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandom(size\u001b[39m=\u001b[39m(\u001b[39m10\u001b[39m, linear\u001b[39m.\u001b[39mdim_out))\n\u001b[0;32m     83\u001b[0m new_x \u001b[39m=\u001b[39m x \u001b[39m+\u001b[39m h\n\u001b[1;32m---> 84\u001b[0m new_w \u001b[39m=\u001b[39m linear\u001b[39m.\u001b[39;49mparams[\u001b[39m'\u001b[39;49m\u001b[39mW\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m+\u001b[39;49m h\n\u001b[0;32m     85\u001b[0m new_b \u001b[39m=\u001b[39m linear\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m h\n\u001b[0;32m     86\u001b[0m new_linear \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(linear)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'float'"
     ]
    }
   ],
   "source": [
    "# sanity check, output must be from o(e-5)\n",
    "initializer = lambda x, y: np.random.normal(size=(y, x))\n",
    "linear = LinearLayer(5, 10, initializer, reg=True, alpha=0.001)\n",
    "check_gradient_linear(linear, h=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LinearLayer:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.W = np.random.randn(input_dim, output_dim)  # Initialize weights\n",
    "        self.b = np.zeros(output_dim)  # Initialize biases\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        output_tensor = np.dot(input_tensor, self.W) + self.b  # Linear transformation\n",
    "        return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a linear layer with input size of 10 and output size of 5\n",
    "linear_layer = LinearLayer(10, 5)\n",
    "\n",
    "# Generate a random input tensor of size (batch_size=32, input_dim=10)\n",
    "input_tensor = np.random.randn(32, 10)\n",
    "\n",
    "# Apply the linear layer to the input tensor\n",
    "output_tensor = linear_layer.forward(input_tensor)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(output_tensor.shape)  # Should print (32, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(x):\n",
    "  return np.maximum(0.0,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer_one:\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        self.w=np.random.randn(input_dim,output_dim)\n",
    "        self.b=np.random.randn(output_dim)\n",
    "    def feadforward(self,input_tensor):    \n",
    "        output_tensor=np.dot(input_tensor,self.w)+self.b\n",
    "        a1=ReLU(output_tensor)\n",
    "        return a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer_one=LinearLayer_one(10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor=np.random.randn(2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.53580293],\n",
       "       [3.14522591, 3.383055  , 1.57220159, 6.71276427, 0.        ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_tensor_one=linear_layer_one.feadforward(input_tensor)\n",
    "output_tensor_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1367874  -0.23286428 -0.32579167 -0.53040458  0.75664197]\n",
      " [-1.11310777 -0.77411317 -0.02242892  0.35389126 -0.79398775]\n",
      " [ 1.20670768  0.79369066 -0.34488965 -1.24072979 -1.29276659]\n",
      " [-0.76635145 -0.72058776 -0.49380762 -0.52503982 -0.50781758]\n",
      " [ 0.96273641  1.20822114 -0.17574588 -0.5961679  -0.86746196]\n",
      " [-0.76499619 -1.16634606  0.30786189 -1.12932609 -0.65431162]\n",
      " [ 0.60338213 -0.502229   -1.69536933 -1.05050439 -0.35504377]\n",
      " [-1.65156502  0.86552438  1.20877213  0.69910553 -1.31588102]\n",
      " [-0.01137571  1.0146634   1.01867949  1.8898846  -0.55646994]\n",
      " [-0.49512409 -0.24811363 -1.27705421 -0.38223056  3.16535961]]\n",
      "[-1.54861716 -0.44903904 -1.95012071  1.66703741  0.43372754]\n"
     ]
    }
   ],
   "source": [
    "print(linear_layer_one.w)\n",
    "print(linear_layer_one.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_grad = np.random.randn(*output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer:\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        self.w=np.random.randn(input_dim,output_dim)\n",
    "        self.b=np.zeros(output_dim)\n",
    "    def feadforward(self,input_tensor):  \n",
    "        self.input_tensor=input_tensor  \n",
    "        output_tensor=np.dot(input_tensor,self.w)+self.b\n",
    "        return output_tensor\n",
    "    def backward(self,output_grad):\n",
    "        self.grade_w=np.dot(self.input_tensor.T,output_grad)\n",
    "        self.grade_b=np.sum(output_grad,axis=0)\n",
    "        \n",
    "    def step(self,learning_rate):\n",
    "        self.w -=learning_rate*self.grade_w\n",
    "        self.b -= learning_rate*self.grade_b\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.41094223 -0.0262169  -1.07205475 -0.68575593  0.82532334]\n",
      " [ 0.04871429  0.91754414  0.1522285   0.76478841  1.08026645]\n",
      " [ 0.46206882  1.53223458 -1.28646262  1.45024206 -0.77442344]\n",
      " [-0.7135635  -0.73871292 -0.28803107  0.31147536 -1.06405336]\n",
      " [-1.34895591  1.47565554  1.63988463  0.30049018  1.52288718]\n",
      " [-0.57776417  0.05235745 -0.65990779 -1.45893937  1.11885795]\n",
      " [-0.10361368  0.19886739  0.2860816   1.32978821  2.10717046]\n",
      " [ 1.68828836  0.39978042 -1.42240389 -0.08420041  0.2872899 ]\n",
      " [ 0.39717345 -0.76570608  0.84521165  1.98575885 -1.08113079]\n",
      " [-0.74165673 -1.3471711  -0.28278399  0.85756265 -0.07763194]]\n",
      "[ 0.20108655  0.10100027  0.43292934  0.09417513 -0.13156326]\n"
     ]
    }
   ],
   "source": [
    "# Create a linear layer with input size of 10 and output size of 5\n",
    "linear_layer = LinearLayer(10, 5)\n",
    "\n",
    "# Generate a random input tensor of size (batch_size=32, input_dim=10)\n",
    "input_tensor = np.random.randn(32, 10)\n",
    "\n",
    "# Apply the linear layer to the input tensor\n",
    "output_tensor = linear_layer.feadforward(input_tensor)\n",
    "\n",
    "# Generate a random gradient of the same shape as the output tensor\n",
    "output_grad = np.random.randn(*output_tensor.shape)\n",
    "\n",
    "# Compute the gradient of the input tensor using the backward method\n",
    "input_grad = linear_layer.backward(output_grad)\n",
    "\n",
    "# Update the weights and biases using the step method with a learning rate of 0.1\n",
    "linear_layer.step(0.1)\n",
    "\n",
    "# Print the updated weights and biases\n",
    "print(linear_layer.w)\n",
    "print(linear_layer.b)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implimented with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Input\n",
    "from keras import Sequential\n",
    "from keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from keras.activations import sigmoid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)      \n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tf = linear_layer(X_train)\n",
    "prediction_np = np.dot( X_train, set_w) + set_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[-1.5891801],\n",
       "       [-3.1783602]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[300.],\n",
       "       [500.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.set_weights([set_w,set_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_tf=linear_layer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[300.],\n",
       "       [500.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, input_dim=1,  activation = 'sigmoid', name='L1')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights([set_w, set_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's Building an Image Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
